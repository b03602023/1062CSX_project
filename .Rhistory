res    = httr::GET(url)
posts  = content(res)
res = POST("https://graph.facebook.com/v2.12/me/feed",
body=list(message=sprintf("[TEST Posting Message] %s At %s","httr 測試",Sys.time()),
access_token=token))
postId = content(res)$id
postId
url = sprintf("https://graph.facebook.com/v2.12/%s?access_token=%s", postId, token)
res = DELETE(url)
content(res)
res
res
posts
View(posts)
posts$posts$data
posts$posts$data$message
posts$posts$data
res = POST("https://graph.facebook.com/v2.12/me/feed",
body=list(message=sprintf("[TEST Posting Message] %s At %s","httr 測試",Sys.time()),
access_token=token))
res
posts
posts$posts$data[[5]]$message
posts
posts[["posts"]][["paging"]][["next"]]
temp=list()
for(c in 1:5){
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
url = posts$posts$paging$next
}
posts$posts$paging$next
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
posts$posts$paging$next
posts
temp=list()
for(c in 1:5){
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
url = posts$posts$paging$`next`
}
url
temp=list()
for(c in 1:5){
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp = append(temp,posts)
url = posts$posts$paging$`next`
}
posts
posts$id
View(posts)
temp
posts$id
for(c in 1:5){
#token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
#prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
#url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp = append(temp,posts)
url = posts$posts$paging$`next`
}
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp=list()
temp = append(temp,posts)
url = posts$posts$paging$`next`
for(c in 1:5){
#token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
#prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
#url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp = append(temp,posts)
url = posts$posts$paging$`next`
}
url
url = posts$posts$paging$`next`
url
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
res
posts  = content(res)
library(httr)
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp=list()
temp = append(temp,posts)
url = posts$posts$paging$`next`
url
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
url
View(posts)
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
View(posts)
temp=list()
temp = append(temp,posts)
url = posts$posts$paging$`next`
for(c in 1:5){
#token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
#prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
#url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp = append(temp,posts)
url = posts$posts$paging$`next`
}
library(httr)
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp=list()
temp = append(temp,posts)
url = posts$posts$paging$`next`
#token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
#prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
#url    = paste0(prefex, token)
res    = httr::GET(url)
res
posts  = content(res)
posts
temp = append(temp,posts)
temp
url = posts$posts$paging$`next`
View(temp)
View(posts)
for(c in 1:5){
#token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
#prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
#url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp = append(temp,posts)
url = posts$posts$paging$`next`
}
View(posts)
View(posts)
for(c in 1:5){
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp = append(temp,posts)
url = posts$posts$paging$`next`
}
temp=list()
for(c in 1:5){
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp = append(temp,posts)
url = posts$posts$paging$`next`
}
View(temp)
View(posts)
View(temp)
View(temp)
temp=list()
for(c in 1:2){
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
temp = append(temp,posts)
url = posts$posts$paging$`next`
}
View(posts)
View(temp)
posts[["posts"]][["paging"]][["next"]]
temp[["posts"]][["paging"]][["next"]]
temp[["posts"]][["paging"]][["next"]] == posts[["posts"]][["paging"]][["next"]]
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
posts=list()
for(c in 1:3){
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
temp  = content(res)
posts = append(temp,posts)
url = posts$posts$paging$`next`
}
View(posts)
View(temp)
library(httr)
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
posts=list()
for(c in 1:5){
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
temp  = content(res)
posts = append(temp,posts)
url = posts$posts$paging$`next`
}
View(posts)
View(temp)
View(posts)
View(posts)
View(posts)
View(temp)
posts$posts$data
?paste0
?paste
library(rvest)
url = https://udn.com/news/cate/2/7225
url = "https://udn.com/news/cate/2/7225"
res = read_html(url)
res
View(res)
a = html_nodes(res, "h2")
a
content(a)
View(posts)
posts[["posts"]][["paging"]][["next"]]
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
posts[["posts"]][["paging"]][["next"]]
posts[["posts"]][["paging"]][["next"]] == url
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
posts[["posts"]][["paging"]][["next"]] == url
posts[["posts"]][["paging"]][["next"]]
View(posts)
View(posts)
token  = "EAACEdEose0cBAEdvZCE1C2g4rWepyX1DwggxJRl4BPVUD7QeyuKLYiDMzuqeEbXEX59vW2cEvbOZAEmsQfAl084x2RJCFxDGu2UOtCJbsCRma54ao6hZAdPvYwkDLPvt65GmIm84vxWd3hJ10Wi3hPNfFDgeHHs9vEu33W8IgJGBr1yWfbIZAGZAZBZAETpND0ZD"
prefex = "https://graph.facebook.com/v2.12/twTOEFL/?fields=posts&access_token="
url    = paste0(prefex, token)
res    = httr::GET(url)
posts  = content(res)
install.packages("Rfacebook")
?install_github
library(devtools)
?install_github
require("Rfacebook")
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
#---------參考的code (可以解決載入較舊頁面的問題)-------
rm(list=ls(all.names=TRUE))
ls()
require("Rfacebook")
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
me <- getUsers("me", token, private_info = TRUE)
me$name
#---------Rfacebook--------
token = "EAACEdEose0cBAKya0xRyk8vu2DNOEW77eoIHZBG7G2kbEZAwfHvqpaHq9eq2CUMod3LYYNnCQ3VnEQHGZCEer1ZCXDjXHgNlIqZCgYkDXB18BHnsLn4ZCLYlcbELCrTpAyFQIGS4ZBZAoQEtISaqLmCtba1034jZCTj1DkNIZBgSsVozEiOwRQIyauAfvZCYqxGKKAi2Pe1z8TFIAZDZD"
me <- getUsers("me", token, private_info = TRUE)
me$name
require("Rfacebook")
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
http://localhost:1410/
require("Rfacebook")
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
?regexpr
?ggplot
library(ggp)
library(ggploy2)
library(ggplot2)
?ggplot
str(CO2)
CO2
head(CO2)
str(CO2)
just <- ggplot(data = CO2)
just
#------week 4 -practice for ggplot--------
justplot <- ggplot(data = CO2)
+geom_boxplot(data=CO2, aes(x=conc,
y=uptake, colour=Plant))
+geom_point(data=CO2, aes(x=conc, y=uptake,
colour=Plant))
#------week 4 -practice for ggplot--------
library(ggplot2)
justplot <- ggplot(data = CO2)
+geom_boxplot(data=CO2, aes(x=conc,
y=uptake, colour=Plant))
justplot+geom_boxplot(data=CO2, aes(x=conc,
y=uptake, colour=Plant))
+geom_point(data=CO2, aes(x=conc, y=uptake,
colour=Plant))
justplot
+geom_boxplot(data=CO2, aes(x=conc,
y=uptake, colour=Plant))
ggplot(data = CO2)+
geom_boxplot(data=CO2, aes(x=conc,
y=uptake, colour=Plant))+
geom_point(data=CO2, aes(x=conc, y=uptake,
colour=Plant))
ggplot(data = CO2)+
geom_boxplot(data=CO2, aes(x=conc,
y=uptake, colour=Plant))+
geom_point(data=CO2, aes(x=conc, y=uptake,
colour=Plant))+
stat_smooth(data=CO2, aes(x=conc,y=uptake))
session_info()
?summarise
filenames <- list.files(getwd(), pattern="*.txt")  #pattern: an optional regular expression. Only file names which match the regular expression will be returned.
filenames
filenames <- list.files(getwd(), pattern="*.txt")  #pattern: an optional regular expression. Only file names which match the regular expression will be returned.
filenames
setwd("D:/D disk/unicourse/106shia/github/1062CSX_project")
getwd()
filenames <- list.files(getwd(), pattern="*.txt")  #pattern: an optional regular expression. Only file names which match the regular expression will be returned.
filenames
?readLines
readLines(1.txt)
readLines("1.txt")
files <- lapply(filenames, readLines)  #Read some or all text lines from a connection.
files
View(files)
files[[1]]
#要做文字雲 抓一些需要用的套件
#從電腦讀檔（仰賴 NLP/tm 這兩個函式庫）
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
?content_transformer
?VectorSource
VectorSource(files)
V=VectorSource(files)
summary(V)
class(C)
class(V)
mode(V)
View(V)
filenames
?Corpus
docs <- Corpus(VectorSource(files))  #Representing and computing on corpora(語料庫).
View(docs)
docs[["1"]][["content"]]
View(docs)
View(files)
files[[1]]
docs[["1"]]
docs[["2"]]
docs[["1"]][["content"]]
files[[1]]
# tm_map(x, FUN, ...)
# Interface to apply transformation functions (also denoted as mappings) to corpora.
# x: A corpus. 語料庫("Corpus" is a collection of text documents.)
# FUN: a transformation function taking a text document (a character vector when x is a SimpleCorpus) as input and returning a text document (a character vector of the same length as the input vector for SimpleCorpus). The function content_transformer can be used to create a wrapper to get and set the content of text documents.
docs <- tm_map(docs,toSpace,"V1")
#要清洗掉的東西
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}     # Create content transformers, i.e., functions which modify the content of an R objec
# gsub performs replacement of all matches.(以空白取代)
#定義清洗：清洗就是把你找到的符號用空白取代
)
# tm_map(x, FUN, ...)
# Interface to apply transformation functions (also denoted as mappings) to corpora.
# x: A corpus. 語料庫("Corpus" is a collection of text documents.)
# FUN: a transformation function taking a text document (a character vector when x is a SimpleCorpus) as input and returning a text document (a character vector of the same length as the input vector for SimpleCorpus). The function content_transformer can be used to create a wrapper to get and set the content of text documents.
docs <- tm_map(docs,toSpace,"V1")
View(docs)
View(docs)
docs[["1"]][["content"]]
View(files)
docs <- tm_map(docs,toSpace,"\n")
docs <- tm_map(docs,toSpace, "1")
docs <- tm_map(docs,toSpace, "的")
docs <- tm_map(docs,toSpace, "及")
docs <- tm_map(docs,toSpace, "為")
docs <- tm_map(docs,toSpace, "是")
docs <- tm_map(docs,toSpace, "在")
docs <- tm_map(docs,toSpace, "我")
docs <- tm_map(docs,toSpace, "沒有")
docs <- tm_map(docs,toSpace, "不要")
docs <- tm_map(docs,toSpace, "只")
docs <- tm_map(docs,toSpace, "正要")
docs <- tm_map(docs,toSpace, "尤其")
docs <- tm_map(docs,toSpace, "做")
docs <- tm_map(docs,toSpace, "活動")
docs <- tm_map(docs,toSpace, "停止")
docs <- tm_map(docs,toSpace, "一下")
docs <- tm_map(docs,toSpace, "進行")
View(docs)
docs[["1"]][["content"]]
docs <- tm_map(docs,toSpace, "[A-Za-z0-9]")
View(docs)
docs[["1"]][["content"]]
?getContent
library(tmcn)
library(rvest)
pttTestFunction <- function(URL, filename)
{
#URL = "https://www.ptt.cc/bbs/NTUcourse/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)),
href = href)
data = data[-c(1:10),]
getContent <- function(x) {
url = paste0("https://www.ptt.cc", x)
tag = html_node(read_html(url), 'div#main-content.bbs-screen.bbs-content')
text = toUTF8(html_text(tag))
}
#getContent(data$href[1])
allText = sapply(data$href, getContent)
allText
#out <- file(filename, "w", encoding="BIG-5")
write.table(allText, filename)
#close(out)
}
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/NTUcourse/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
install.packages("tmcn")
library(tmcn)
library(rvest)
pttTestFunction <- function(URL, filename)
{
#URL = "https://www.ptt.cc/bbs/NTUcourse/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)),
href = href)
data = data[-c(1:10),]
getContent <- function(x) {
url = paste0("https://www.ptt.cc", x)
tag = html_node(read_html(url), 'div#main-content.bbs-screen.bbs-content')
text = toUTF8(html_text(tag))
}
#getContent(data$href[1])
allText = sapply(data$href, getContent)
allText
#out <- file(filename, "w", encoding="BIG-5")
write.table(allText, filename)
#close(out)
}
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/NTUcourse/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
?stemDocument
#進行文本清理
#par(family='STKaiti')  #字體設定；讓文字顯示成中文
par(family=("Heiti TC Light"))
