me$name
require("Rfacebook")
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
?fbOAuth
fbOAuth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
token = "EAACEdEose0cBAPWqw5JDTSaYbWgWYcCsGJ11ZAuZBbFR6ZAZBlahtxdas6Sk2ERLKRBW1V3rZCJNjXo1Fp26ABZA85gyiLgi85fDhUt4CbwTIZBcLTUmsZCZCJNUwKvpCW2o5m2DxSWvby8TS5v0ETvk2srZB7UvU43TvcVPlR6pcz4CaFMvLYQxnZB92efbGzrZAX8ZD"
library(Rfacebook)
me <- getUsers("me", token, private_info = TRUE)
me$name
require("Rfacebook")
fbOAuth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
fbOAuth
#---------Rfacebook--------
token = "EAACEdEose0cBAPWqw5JDTSaYbWgWYcCsGJ11ZAuZBbFR6ZAZBlahtxdas6Sk2ERLKRBW1V3rZCJNjXo1Fp26ABZA85gyiLgi85fDhUt4CbwTIZBcLTUmsZCZCJNUwKvpCW2o5m2DxSWvby8TS5v0ETvk2srZB7UvU43TvcVPlR6pcz4CaFMvLYQxnZB92efbGzrZAX8ZD"
library(Rfacebook)
me <- getUsers("me", token, private_info = TRUE)
me$name
require("Rfacebook")
fbOAuth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
me <- getUsers("me",token=fb.oauth)
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
me <- getUsers("me",token=fb.oauth)
me$name
token = "EAACEdEose0cBAPWqw5JDTSaYbWgWYcCsGJ11ZAuZBbFR6ZAZBlahtxdas6Sk2ERLKRBW1V3rZCJNjXo1Fp26ABZA85gyiLgi85fDhUt4CbwTIZBcLTUmsZCZCJNUwKvpCW2o5m2DxSWvby8TS5v0ETvk2srZB7UvU43TvcVPlR6pcz4CaFMvLYQxnZB92efbGzrZAX8ZD"
library(Rfacebook)
me <- getUsers("me", token, private_info = TRUE)
me$name
install.packages("httpuv")
install.packages("httpuv")
library(httpuv)
require("Rfacebook")
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE,
type = "application/x-www-form-urlencoded"
)
require("Rfacebook")
fb.oauth <- fbOAuth(
app_id="599990343682885",
app_secret="5162044ac94f64461ed587312d424521",
extended_permissions = TRUE)
wordcloud(g_freqFrame$Var1,g_freqFrame$Freq,
scale=c(5,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:20)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
library(Matrix)   #nnzero
library(wordcloud2)
tres <- 10
g_freqFrame = as.data.frame(table(unlist(g_seg)))
library(httr)
pageno <- 1:10    #搜尋頁數
g_url <- paste0("https://ecshweb.pchome.com.tw/search/v3.3/all/results?q=%E5%A5%B3%E8%A3%9D&page=", pageno, "&sort=rnk/dc")
b_url <- paste0("https://ecshweb.pchome.com.tw/search/v3.3/all/results?q=%E7%94%B7%E8%A3%9D&page=", pageno, "&sort=rnk/dc")
#url = "https://ecshweb.pchome.com.tw/search/v3.3/all/results?q=%E5%A5%B3&page=1&sort=rnk/dc"
g_prods = character()
b_prods = character()
getcontent <- function(url, prods){
for(i in 1:length(pageno)){
res = GET(url[i])
res_json = httr::content(res)
results <- data.frame(do.call(rbind,res_json$prods))
prods[((pageno[i]-1)*20+1):(pageno[i]*20)] <- unlist(results$name)
}
return(prods)
}
g_prods <- c(g_prods, getcontent(g_url, g_prods))
Sys.sleep(60)
b_prods <- c(b_prods, getcontent(b_url, b_prods))
library(Matrix)   #nnzero
library(wordcloud2)
tres <- 10
g_freqFrame = as.data.frame(table(unlist(g_seg)))
#-------clean data--------
processdata <- function(prods){
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)      #斷詞用
library(RColorBrewer)
library(wordcloud)
library(tmcn)   #segmentCN
docs <- Corpus(VectorSource(prods))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs,toSpace,"V1")
docs <- tm_map(docs,toSpace,"\n")
docs <- tm_map(docs,toSpace, "1")
# 清除大小寫英文與數字
docs <- tm_map(docs,toSpace, "[A-Za-z0-9]")
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
#-------斷詞--------
mixseg = worker()
#new_user_word(mixseg,segment)   #Add user word
#斷詞  mixseg[groups]
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
#1
seg = lapply(docs, jieba_tokenizer)
#2
seg = lapply(docs, segmentCN)
#seg = lapply(seg, strsplit, " ")
return(seg)
}
g_seg <- processdata(g_prods)
b_seg <- processdata(b_prods)
library(Matrix)   #nnzero
library(wordcloud2)
tres <- 10
g_freqFrame = as.data.frame(table(unlist(g_seg)))
# 將女裝關鍵字去除
wordcloud2(g_freqFrame[(g_freqFrame$Freq>tres)&(g_freqFrame$Freq!=max(g_freqFrame$Freq)),], fontFamily = "微軟雅黑",color = "random-light", backgroundColor = "grey", size = 1
)
windowsFonts(TC=windowsFont("Heiti TC Light"))
wordcloud(g_freqFrame$Var1,g_freqFrame$Freq,
scale=c(5,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:20)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(g_freqFrame$Var1,g_freqFrame$Freq,
scale=c(5,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(b_freqFrame$Var1,b_freqFrame$Freq,
scale=c(5,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
b_freqFrame = as.data.frame(table(unlist(b_seg)))
tres <-10
windowsFonts(TC=windowsFont("Heiti TC Light"))
wordcloud(b_freqFrame$Var1,b_freqFrame$Freq,
scale=c(5,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
library(rvest)
page <- 0:12
p <- 48*(page)
u_getrvest <- function(url){
res <- read_html(url)
raw.titles <- res %>% html_nodes("div.unit .info .name")
u_prods <- raw.titles %>% html_node("a") %>% html_attr('title')
return(u_prods)
}
ug_url <- paste0("http://www.uniqlo.com/tw/store/search?qtext=%E5%A5%B3%E8%A3%9D&qbrand=10&qclv1=&qclv25=&qclv2=&qrange=&qcolor=&qsize=&qnew=&qdiscount=&qlimit=&qmulti=&qonline=&qspsize=&qstart=", p,"&sort=goods_disp_priority")
ug_prods <- mapply(u_getrvest, ug_url)
colnames(ug_prods) <- page+1
#raw.prices <- res %>% html_nodes("dd.price") %>% html_text
#raw.prices <- as.character(raw.prices)
#gsub("NT$", "", raw.prices)
ug_seg <- processdata(as.character(ug_prods))
ug_freqFrame = as.data.frame(table(unlist(ug_seg)))
tres <-10
windowsFonts(TC=windowsFont("Heiti TC Light"))
wordcloud(ug_freqFrame$Var1,ug_freqFrame$Freq,
scale=c(5,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:17)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(ug_freqFrame$Var1,ug_freqFrame$Freq,
scale=c(5,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
ub_url <- paste0("http://www.uniqlo.com/tw/store/search?qtext=%E7%94%B7%E8%A3%9D&qbrand=10&qclv1=&qclv25=&qclv2=&qrange=&qcolor=&qsize=&qnew=&qdiscount=&qlimit=&qmulti=&qonline=&qspsize=&qstart=", p,"&sort=goods_disp_priority")
ub_prods <- mapply(u_getrvest, ub_url)
colnames(ub_prods) <- page+1
#raw.prices <- res %>% html_nodes("dd.price") %>% html_text
#raw.prices <- as.character(raw.prices)
#gsub("NT$", "", raw.prices)
ub_seg <- processdata(as.character(ub_prods))
ub_freqFrame = as.data.frame(table(unlist(ub_seg)))
tres <-10
windowsFonts(TC=windowsFont("Heiti TC Light"))
wordcloud(ub_freqFrame$Var1,ub_freqFrame$Freq,
scale=c(5,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
ub_freqFrame
?wordcloud
wordcloud(g_freqFrame$Var1,g_freqFrame$Freq,
scale=c(10,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(g_freqFrame$Var1,g_freqFrame$Freq,
scale=c(5,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(g_freqFrame$Var1,g_freqFrame$Freq,
scale=c(10,0.5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
#-------詞頻-------
freqFramecbind(ub_freqFrame, ug_freqFrame, b_freqFrame, g_freqFrame)
#-------詞頻-------
freqFrame <- cbind(ub_freqFrame, ug_freqFrame, b_freqFrame, g_freqFrame)
wordcloud(ub_freqFrame$Var1,ub_freqFrame$Freq,
scale=c(10,5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(ub_freqFrame$Var1,ub_freqFrame$Freq,
scale=c(10,0.1),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(ub_freqFrame$Var1,ub_freqFrame$Freq,
scale=c(10,0.9),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(ub_freqFrame$Var1,ub_freqFrame$Freq,
scale=c(10,1),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(ub_freqFrame$Var1,ub_freqFrame$Freq,
scale=c(20,5),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(ub_freqFrame$Var1,ub_freqFrame$Freq,
scale=c(20,3),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(ub_freqFrame$Var1,ub_freqFrame$Freq,
scale=c(15,1),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
wordcloud(ub_freqFrame$Var1,ub_freqFrame$Freq,
scale=c(10,1),
min.freq=5,max.words=50,
random.order=FALSE,random.color=FALSE,
rot.per=.2, colors=brewer.pal(11, "Paired")[c(1:25)],
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE,family="TC")
#-------詞頻-------
freqFrame <- merge(ub_freqFrame, ug_freqFrame, b_freqFrame, g_freqFrame)
#-------詞頻-------
freqFrame <- merge(ub_freqFrame, ug_freqFrame, b_freqFrame, g_freqFrame, all.x = TRUE)
ub_freqFrame
#-------詞頻-------
freqFrame <- merge(ub_freqFrame, ug_freqFrame, b_freqFrame, g_freqFrame,
by = "Var1")
?merge
#-------詞頻-------
g_seg <- Corpus(VectorSource(g_seg))
g_tdm <- TermDocumentMatrix(g_seg, control = list(wordLengths = c(1,10)))
g_tf <- as.matrix(g_tdm)/apply(g_tdm, 2, sum)   #term frequency: the number of words in every document
g_idf <- log10(ncol(g_tdm)/apply(g_tdm, 1, nnzero))
g_tfidf <- g_tf*g_idf       #TF-IDF
g_tfidf
View(head(g_tfidf[order(g_tfidf, decreasing = TRUE)]))       #TF-IDF
View(head(g_tfidf[order(g_tfidf, decreasing = TRUE),]))       #TF-IDF
head(g_tfidf[order(g_tfidf, decreasing = TRUE),])
g_tfidf[order(g_tfidf, decreasing = TRUE),]
g_tfidf
g_tfidf <- apply(g_tfidf, 1, sum)
View(head(g_tfidf[order(g_tfidf, decreasing = TRUE),]))       #TF-IDF
g_tfidf
View(head(g_tfidf[order(g_tfidf, decreasing = TRUE)]))       #TF-IDF
View(g_tfidf[order(g_tfidf, decreasing = TRUE)])       #TF-IDF
?head
View(head(g_tfidf[order(g_tfidf, decreasing = TRUE)], n = 15L))       #TF-IDF
g_tf <- as.matrix(g_tdm)/apply(g_tdm, 2, sum)   #term frequency: the number of words in every document
g_idf <- log10(ncol(g_tdm)/apply(g_tdm, 1, nnzero))
g_tfidf <- g_tf*g_idf       #TF-IDF
g_tfidf <- apply(g_tfidf, 1, sum)
View(head(g_tfidf[order(g_tfidf, decreasing = TRUE)], n = 15L))       #TF-IDF
b_tf <- as.matrix(b_tdm)/apply(b_tdm, 2, sum)   #term frequency: the number of words in every document
b_idf <- log10(ncol(b_tdm)/apply(b_tdm, 1, nnzero))
b_tfidf <- b_tf*b_idf       #TF-IDF
b_tfidf <- apply(b_tfidf, 1, sum)
View(head(b_tfidf[order(b_tfidf, decreasing = TRUE)], n = 15L))       #TF-IDF
ug_tf <- as.matrix(ug_tdm)/apply(ug_tdm, 2, sum)   #term frequency: the number of words in every document
ug_idf <- log10(ncol(ug_tdm)/apply(ug_tdm, 1, nnzero))
ug_tfidf <- ug_tf*ug_idf       #TF-IDF
ug_tfidf <- apply(ug_tfidf, 1, sum)
View(head(ug_tfidf[order(ug_tfidf, decreasing = TRUE)], n = 15L))       #TF-IDF
ub_tf <- as.matrix(ub_tdm)/apply(ub_tdm, 2, sum)   #term frequency: the number of words in every document
ub_idf <- log10(ncol(ub_tdm)/apply(ub_tdm, 1, nnzero))
ub_tfidf <- ub_tf*ub_idf       #TF-IDF
ub_tfidf <- apply(ub_tfidf, 1, sum)
View(head(ub_tfidf[order(ub_tfidf, decreasing = TRUE)], n = 15L))       #TF-IDF
b_tf <- as.matrix(b_tdm)/apply(b_tdm, 2, sum)   #term frequency: the number of words in every document
b_seg <- Corpus(VectorSource(b_seg))
b_tdm <- TermDocumentMatrix(b_seg, control = list(wordLengths = c(1,10)))
b_tf <- as.matrix(b_tdm)/apply(b_tdm, 2, sum)   #term frequency: the number of words in every document
b_idf <- log10(ncol(b_tdm)/apply(b_tdm, 1, nnzero))
b_tfidf <- b_tf*b_idf       #TF-IDF
b_tfidf <- apply(b_tfidf, 1, sum)
View(head(b_tfidf[order(b_tfidf, decreasing = TRUE)], n = 15L))       #TF-IDF
ug_seg <- Corpus(VectorSource(ug_seg))
ug_tdm <- TermDocumentMatrix(ug_seg, control = list(wordLengths = c(1,10)))
ug_tf <- as.matrix(ug_tdm)/apply(ug_tdm, 2, sum)   #term frequency: the number of words in every document
ug_idf <- log10(ncol(ug_tdm)/apply(ug_tdm, 1, nnzero))
ug_tfidf <- ug_tf*ug_idf       #TF-IDF
ug_tfidf <- apply(ug_tfidf, 1, sum)
View(head(ug_tfidf[order(ug_tfidf, decreasing = TRUE)], n = 15L))       #TF-IDF
ub_seg <- Corpus(VectorSource(ub_seg))
ub_tdm <- TermDocumentMatrix(ub_seg, control = list(wordLengths = c(1,10)))
ub_tf <- as.matrix(ub_tdm)/apply(ub_tdm, 2, sum)   #term frequency: the number of words in every document
ub_idf <- log10(ncol(ub_tdm)/apply(ub_tdm, 1, nnzero))
ub_tfidf <- ub_tf*ub_idf       #TF-IDF
ub_tfidf <- apply(ub_tfidf, 1, sum)
View(head(ub_tfidf[order(ub_tfidf, decreasing = TRUE)], n = 15L))       #TF-IDF
library(httr)
pageno <- 1:10    #搜尋頁數
g_url <- paste0("https://ecshweb.pchome.com.tw/search/v3.3/all/results?q=%E5%A5%B3%E8%A3%9D&page=", pageno, "&sort=rnk/dc")
b_url <- paste0("https://ecshweb.pchome.com.tw/search/v3.3/all/results?q=%E7%94%B7%E8%A3%9D&page=", pageno, "&sort=rnk/dc")
#url = "https://ecshweb.pchome.com.tw/search/v3.3/all/results?q=%E5%A5%B3&page=1&sort=rnk/dc"
g_prods = character()
b_prods = character()
getcontent <- function(url, prods){
for(i in 1:length(pageno)){
res = GET(url[i])
res_json = httr::content(res)
results <- data.frame(do.call(rbind,res_json$prods))
prods[((pageno[i]-1)*20+1):(pageno[i]*20)] <- unlist(results$name)
}
return(prods)
}
g_prods <- c(g_prods, getcontent(g_url, g_prods))
Sys.sleep(60)
View(head(g_tfidf[order(g_tfidf, decreasing = TRUE)], n = 15L))       #TF-IDF
data <- read.csv("titanicTrain.csv")
setwd("D:/D disk/unicourse/106shia/github/1062CSX_project/week_8/project_3")
data <- read.csv("titanicTrain.csv")
data
data <- read.csv("titanicTrain.csv")
View(data)
data$boat
data$boat[1]
data$boat[2]
data$boat[3]
class(data$boat[3])
class(data$boat[3])
mode(data$boat[3])
length(data$boat[3])
length(data$boat[1])
as.numeric(data$boat[1])
data$boat[1]
as.character(data$boat[1])
data$boat <- as.character(data$boat)
data$boat[3]
data$boat[3] == ""
data$boat == ""
data$survived[data$boat == ""]
# 去除NA
data <- data[1:1000,]
data$boat <- as.character(data$boat)
data$survived[data$boat == ""]
data$survived[data$boat != ""]
# age 越小，越有可能上船，但不一定會存活?
plot(data$survived, data$age)
# age 越小，越有可能上船，但不一定會存活?
barplot(data$survived, data$age)
# age 越小，越有可能上船，但不一定會存活?
plot(data$survived, data$age)
# age 越小，越有可能上船，但不一定會存活?
data$age[data$survived]
data$survived
# age 越小，越有可能上船，但不一定會存活?
data$age[data$survived==1]
# age 越小，越有可能上船，但不一定會存活?
plot(data$age[data$survived==1])
# age 越小，越有可能上船，但不一定會存活?
hist(data$age[data$survived==1])
# age 越小，越有可能上船，但不一定會存活?
hist(data$age[data$survived==1], title = "the age histogram for those who were survived" )
?hist
# age 越小，越有可能上船，但不一定會存活?
hist(data$age[data$survived==1], main = "the age histogram for those who were survived" )
# 船票價的影響
data$fare[data$survived==1]
hist(data$fare[data$survived==1])
summary(data$fare[data$survived==1])
summary(data$fare)
plot(data$age[data$survived==1], data$fare[data$survived==1])
plot(data$age, data$fare)
plot(data$age[data$survived==1], data$fare[data$survived==1], col="red")
points(data$age, data$fare)
plot(data$age, data$fare)
points(data$age[data$survived==1], data$fare[data$survived==1], col="red")
plot(data$age, data$fare)
points(data$age[data$survived==1], data$fare[data$survived==1], col="red")
points(data$age[data$survived==1 && data$sibsp!=0 && data$parch!=0], data$fare[data$survived==1 && data$sibsp!=0 && data$parch!=0], col="blue")
data$survived==1 && data$sibsp!=0 && data$parch!=0
data$survived==1 & data$sibsp!=0 & data$parch!=0
points(data$age[data$survived==1 & data$sibsp!=0 & data$parch!=0], data$fare[data$survived==1 & data$sibsp!=0 & data$parch!=0], col="blue")
points(data$age[data$survived==1 & data$sibsp!=0 & data$parch!=0 & data$sex=="female"], data$fare[data$survived==1 & data$sibsp!=0 & data$parch!=0 & data$sex=="female"], col="green")
length(data$survived==1 & data$sibsp!=0 & data$parch!=0 & data$sex=="female")/length(data$survived==1 & data$sibsp!=0 & data$parch!=0 )
length(data$survived==1 & data$sibsp!=0 & data$parch!=0 & data$sex=="female")
length(data$survived==1 & data$sibsp!=0 & data$parch!=0 )
data[data$survived==1 & data$sibsp!=0 & data$parch!=0)]
data[data$survived==1 & data$sibsp!=0 & data$parch!=0]
data$age[data$survived==1 & data$sibsp!=0 & data$parch!=0]
length(data$age[data$survived==1 & data$sibsp!=0 & data$parch!=0& data$sex=="female"])/length(data$age[data$survived==1 & data$sibsp!=0 & data$parch!=0])
length(data$age[data$survived==0 & data$sibsp!=0 & data$parch!=0& data$sex=="male"])/length(data$age[data$survived==0 & data$sibsp!=0 & data$parch!=0])
data$survived[data$boat != ""]
data$survived[data$boat == ""]
hist(data$survived[data$boat == ""])
mode(data$survived[data$boat == ""])
class(data$survived[data$boat == ""])
as.factor(data$survived[data$boat == ""])
as.factor(data$survived)
class(as.factor(data$survived))
mode(as.factor(data$survived))
class(data$survived)
as.factor(data$sex)
as.factor(data$sex)[1]
as.factor(data$sex)[2]
as.factor(data$sex)[2] > as.factor(data$sex)[1]
data$survived <- as.factor(data$survived)
data$pclass <- as.factor(data$pclass)
data$survived <- as.factor(data$survived)
data$sex <- as.factor(data$sex)
hist(data$survived[data$boat == ""])
barplot(data$survived[data$boat == ""])
data <- read.csv("titanicTrain.csv")
# 去除NA
data <- data[1:1000,]
barplot(data$survived[data$boat == ""])
summary(data$survived[data$boat != ""])
as.factor(data$survived[data$boat != ""])
summary(as.factor(data$survived[data$boat != ""]))
summary(as.factor(data$survived[data$boat != ""]))[1]
summary(as.factor(data$survived[data$boat == ""]))
summary(as.factor(data$survived[data$boat != ""])) #有登船
summary(as.factor(data$survived[data$boat == ""])) #沒登船
length(as.factor(data$survived[data$boat != ""]))
as.factor(data$survived[data$boat != ""])[1]/length(as.factor(data$survived[data$boat != ""]))
summary(as.factor(data$survived[data$boat != ""]))[1]/length(as.factor(data$survived[data$boat != ""]))
summary(as.factor(data$survived[data$boat == ""]))[1]/length(as.factor(data$survived[data$boat == ""]))
summary(as.factor(data$survived[data$boat == ""]))[2]/length(as.factor(data$survived[data$boat == ""]))
summary(data)
class(data$ticket)
